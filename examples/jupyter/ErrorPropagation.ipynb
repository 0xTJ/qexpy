{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Propagation with QExPy\n",
    "\n",
    "The first step is to import the error module for error propagation. We'll import it as \"e\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import qexpy.error as e\n",
    "#e.set_error_method(\"derivative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll declare two measured values, x and y, with uncertainties, and print them out. We use the Measurement object from the qexpy.error package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 10 +/- 1\n",
      "y = 5 +/- 3\n"
     ]
    }
   ],
   "source": [
    "#Our two measured values:\n",
    "x = e.Measurement(10,1)\n",
    "y = e.Measurement(5,3)\n",
    "\n",
    "#We can print them out:\n",
    "print(\"x =\",x)\n",
    "print(\"y =\",y)\n",
    "#x.set_correlation(y,0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can declare a third object, z, which depends on x and y. The uncertainty in x and y will be correctly propagated to z, so once we have defined z, we can simply print it out with the correct uncertainty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = 15 +/- 3\n"
     ]
    }
   ],
   "source": [
    "#We define z\n",
    "z = x+y\n",
    "#z can now be printed out\n",
    "print(\"z =\",z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the uncertainties have been kept to 1 significant figure. In this case, the error in z was obtained by adding the errors in x and y in quadrature. We can change the number of significant figures to confirm that the errors were indeed added in quadrature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = 15.000 +/- 3.317\n"
     ]
    }
   ],
   "source": [
    "z.set_sigfigs(5)\n",
    "print(\"z =\",z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the error in z to what the errors in x and y are when added manually in quadrature. We need to import the sqrt() function from the math package to apply mathematical functions to numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1622776601683795\n"
     ]
    }
   ],
   "source": [
    "import math as m\n",
    "quadrature = m.sqrt(x.std**2+y.std**2)\n",
    "print(quadrature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Math functions\n",
    "We can propagate the uncertainties through any operator (+,-,\\*,/) automatically as we showed above. QExPy also knows how to propagate the uncertainty in common mathematical functions. To use mathematical functions on Measurement objects, we need to call the functions from the QExPy package (as opposed to the math package as we did above for 2 numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time =  1.2771 +/- 0.0113 seconds\n"
     ]
    }
   ],
   "source": [
    "#If an object fell a distance of 8.0 +/0.1 m, how long did it take to fall?\n",
    "y = e.Measurement(8,0.1)\n",
    "g = 9.81\n",
    "t = e.sqrt(2*y/g)\n",
    "print(\"time = \",t, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error in correlated quantities\n",
    "If we have two measurements, x and y, that are correlated, then their correlation factor will impact the uncertainty on a quantity that depends on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x and y uncorrelated: z= 15.000 +/- 3.317\n",
      "x and y positively correlated: z= 15.000 +/- 3.742\n",
      "x and y negatively correlated: z= 15.000 +/- 2.828\n"
     ]
    }
   ],
   "source": [
    "x = e.Measurement(10,1)\n",
    "y = e.Measurement(5,3)\n",
    "z = x+y\n",
    "print(\"x and y uncorrelated: z=\",z)\n",
    "\n",
    "#Now set a correlation factor between x and y:\n",
    "x.set_correlation(y,0.5)\n",
    "z = x+y\n",
    "print(\"x and y positively correlated: z=\",z)\n",
    "\n",
    "#We can also use the covariance factor instead of the correlation factor:\n",
    "x.set_covariance(y,-1.5)\n",
    "z = x+y\n",
    "print(\"x and y negatively correlated: z=\",z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't specify any correlation factors, then all quantities are assumed to be independent. However, a quantity should not be independent from itself, so QExPy knows how to track the correlation in quantities that depend on common quantities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0000 +/- 0.0000\n"
     ]
    }
   ],
   "source": [
    "x = e.Measurement(10,1)\n",
    "y = x*x\n",
    "z = x*x - y #this should be 0 +/- 0, since it's really x^2 - x^2 \n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Statistical measurements\n",
    "QExPy can also handle the case when you have repeated measurements of a single quantity and you want to average them together. Suppose that you have measured 5 values of some quantity T. QExPy will automatically assume that those values should be averaged together so that T is given by the mean of the measured values with an uncertainty given by the standard deviation of the values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.3000 +/- 0.5431\n"
     ]
    }
   ],
   "source": [
    "T=e.Measurement( [5.6, 4.8, 6.1, 4.9, 5.1 ] )\n",
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T can be used just as any other measurement with uncertainties, and its error will be propagate correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1849 +/- 0.1214\n"
     ]
    }
   ],
   "source": [
    "omega = 2*3.14/T\n",
    "print(omega)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple measurements (Arrays of Measurements)\n",
    "QExPy can also handle the case of having multiple measurements, when each measurement has its own uncertainty. For example, if you have three measurements of a single quantity, in order to get an average value, you should weight each measurement by its uncertainty (or rather the weight should be 1 over the square of the uncertainty). This is handled by the MeasurementArray class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.233 +/- 1.418\n"
     ]
    }
   ],
   "source": [
    "#gvals = e.Measurement_Array([(9.8,0.2), (14,3) , (9.9,0.1)])\n",
    "gvals = e.Measurement_Array([9.8,14,9.9],[0.2,3,0.1])\n",
    "print(gvals.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MeasurementArray object truly is an array of Measurement objects, so individual measurements can be retrieved (remember that the first element in an array in python has index 0 not 1, so element 1 is the second element):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.000 +/- 3.000\n"
     ]
    }
   ],
   "source": [
    "print(gvals[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error propagation methods\n",
    "\n",
    "### Derivative method (default)\n",
    "By default, QExPy propagates the uncertainties using the \"derivative\" method. That is, for a function, $f(x,y)$, that depends on measured quantities $x\\pm\\sigma_x$ and $y\\pm\\sigma_y$, with covariance $\\sigma_{xy}$ between the two measured quantities, the uncertainty in $f$ is given by:\n",
    "$$ \\sigma_f = \\sqrt{ \\left(\\frac{\\partial f}{\\partial x} \\sigma_x \\right)^2 + \\left(\\frac{\\partial f}{\\partial y} \\sigma_y \\right)^2 + 2 \\frac{\\partial f}{\\partial x} \\frac{\\partial f}{\\partial y}\\sigma_{xy} }$$\n",
    "\n",
    "QExPy evaluates the derivatives exactly when propagating the uncertainties using an algorithm called \"automatic differentiation\". This is possible as QExPy internally keeps track of the dependency of quantities on each other, and as an added bonus can also be used to evaluate numerical derivatives exactly. Although the derivative method is commonly taught in undergraduate laboratories, it is only valid when the relative uncertainties in the quantities being propagated are small (e.g. less than ~10% relative uncertainty). This method is thus not strongly encouraged, although it has been made the default because it is so prevalent in undergraduate teaching. \n",
    "\n",
    "\n",
    "### Min-Max method (not recommended)\n",
    "This is not the only way to propagate the uncertainty in $f$. For example, the \"Min-Max\" method, is a method to yield a more conservative (larger) estimate of the uncertainty in $f$ and is often used in introductory courses. The Min-Max method defines the central value and uncertainty in $f$ as:\n",
    "$$f=\\frac{1}{2}(f^{max}+f^{min})$$\n",
    "$$\\sigma_f=\\frac{1}{2}(f^{max}-f^{min})$$\n",
    "\n",
    "where $f^{max}$ ($f^{min}$) is the maximum (minimum) value that $f$ takes when $x$ and $y$ are varied within their uncertainty range. For example, if $f(x,y)=x+y$, then the maximum and minimum of $f$ are easily found:\n",
    "\n",
    "$$f^{max} = (x+\\sigma_x)+(y+\\sigma_y)$$\n",
    "$$f^{min} = (x-\\sigma_x)-(y-\\sigma_y)$$\n",
    "\n",
    "The Min-Max method actually requires a numerical approximation to evaluate the values of $f^{max}$ and $f^{min}$ for all but the most simple cases. Hence although it is a good method to introduce the idea of uncertainty propagation, it is not recommended to use this method in any serious calculation (it also does not take correlations into account). \n",
    "\n",
    "### Monte Carlo method (recommended!)\n",
    "Finally, the recommended method to propagate errors is the \"Monte-Carlo\" method, although it is the hardest to understand. The MC method is based on a statiscal understanding of the measurements. In the QExPy implementation, currently, the main assumptions is that the uncertainty in a quantity is given by a \"standard error\"; that is, if $x = 10\\pm 1$, then we *assume* that this error and uncertainty should be interpreted as: \"if we measure $x$ multiple times, we will obtain a set of measurements that are normally distributed with a mean of 10 and a standard deviation of 1\". In other words, we assume that $x$ has a 68% chance of being in the range between 9 and 11.\n",
    "\n",
    "\n",
    "The MC method then uses the assumption that measured quantities are normally distributed and use this to propagate the errors by using Monte Carlo simulation. Suppose that we have measured $x$ and $y$ and wish to determine the central value and uncertainty in $x=x+y$. The Monte Carlo method will generate normally distributed random values for $x$ and $y$ (the random numbers will be correctly correlated if the user has indicated that $x$ and $y$ are correlated), then it will add those random values together, to obtain a set of values for $z$. The mean and standard deviation of the random values for $z$ are taken as the central value and uncertainty in $z$. \n",
    "\n",
    "## What QExPy actually does\n",
    "Although the user appears to choose the method used to propagate the errors, QExPy always uses all three methods behind the scenes and the user only decides which method to print out. This allows QExPy to compare the results behind the scenes, in particular, to inform the users that the uncertainties using a particular method (e.g. derivative) may be inaccurate and to suggest that the user choose a different method. \n",
    "\n",
    "## Example\n",
    "Below, we illustrate an example of using the different methods to propagate the uncertainty in the Coulomb force based on the measurement of two charges, $q_1$ and $q_2$, and the distance between them, $r$. We illustrate how the derivative method does not give the correct answer if the relative uncertainties in the measured quantities are large. \n",
    "\n",
    "### 1 % relative uncertainty calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative method, F =  18.000 +/- 0.509\n",
      "Min-Max method, F = 18.006 +/- 0.198\n",
      "Monte Carlo method, F = 18.002 +/- 0.442\n"
     ]
    }
   ],
   "source": [
    "#Measurements with 1% relative uncertainties:\n",
    "relative_factor = 0.01 \n",
    "\n",
    "#Measured values\n",
    "q1m=1e-6\n",
    "q2m=2e-5\n",
    "rm=0.1\n",
    "\n",
    "#Convert to Measurement objects\n",
    "q1 = e.Measurement(q1m,relative_factor*q1m)\n",
    "q2 = e.Measurement(q2m,relative_factor*q2m)\n",
    "r = e.Measurement(rm,relative_factor*rm)\n",
    "#Coulomb's constant:\n",
    "k = 9e9 \n",
    "\n",
    "#Define the Force:\n",
    "F = k*q1*q2/r**2\n",
    "\n",
    "#Print out the different errors\n",
    "e.set_error_method(\"derivative\")\n",
    "print(\"Derivative method, F = \",F)\n",
    "e.set_error_method(\"minmax\")\n",
    "print(\"Min-Max method, F =\", F)\n",
    "e.set_error_method(\"mc\")\n",
    "print(\"Monte Carlo method, F =\",F)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 % relative uncertainty calculation\n",
    "We see that in this case, the Monte Carlo method returns a different uncertainty than the derivative method, because the derivative method is incorrect when the uncertainties are this large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative method, F =  18.000 +/- 5.091\n",
      "Min-Max method, F = 18.607 +/- 2.145\n",
      "Monte Carlo method, F = 18.455 +/- 4.780\n"
     ]
    }
   ],
   "source": [
    "#Measurements with 10% relative uncertainties:\n",
    "relative_factor = 0.1 \n",
    "\n",
    "#Measured values\n",
    "q1m=1e-6\n",
    "q2m=2e-5\n",
    "rm=0.1\n",
    "\n",
    "#Convert to Measurement objects\n",
    "q1 = e.Measurement(q1m,relative_factor*q1m)\n",
    "q2 = e.Measurement(q2m,relative_factor*q2m)\n",
    "r = e.Measurement(rm,relative_factor*rm)\n",
    "#Coulomb's constant:\n",
    "k = 9e9 \n",
    "\n",
    "#Define the Force:\n",
    "F = k*q1*q2/r**2\n",
    "\n",
    "#Print out the different errors\n",
    "e.set_error_method(\"derivative\")\n",
    "print(\"Derivative method, F = \",F)\n",
    "e.set_error_method(\"minmax\")\n",
    "print(\"Min-Max method, F =\", F)\n",
    "e.set_error_method(\"mc\")\n",
    "print(\"Monte Carlo method, F =\",F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 11.47639298,  17.00644263,  14.77469285, ...,  21.57077573,\n",
       "        16.23910396,  22.12960132])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.MC_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
